\chapter{Decision Problems}

\section{Games Against Nature}

\section{Games Against an Opponent}

% this will be the last portion of this section, where we bring together
% several concepts. Need to re-write this section: change the context
% of the problem and explain the methodology.
\emph{Nature as an adversary: a two-person zero-sum game.}
Merrill has a concession stand at Target Field for the sale of
sunglasses and umbrellas. This entrepreneur likes to make sales
regardless of the weather.  When it rains can sell about 500
umbrellas.  On a sunny day he can sell about 100 umbrellas and about
1000 sunglasses. Umbrellas cost him 50 cents and sell for \$1.
Sunglasses cost him 20 cents each and sell for 50 cents. Merrill is
willing to invest \$250 in the concession stand business.  All unsold
items represent a loss; there is no salvage value. 

Formulate Merrill's problem as a two-person zero--sum game. Merrill is
the row player and Nature is the column player. Merrill's strategy set
is \{buy inventory for rain, buy inventory for sun\}. Nature's strategy
set is \{rain, sun\}. The payoff entries represent the profit/loss.
Find an equilibrium strategy for Merrill. That is
to say, Merrill treats Nature as a strategic opponent and wants to
find an optimal inventory strategy that will yield a maximum expected
profit \emph{regardless} of the weather.

Would Merrill necessarily need to invest all \$250 into buying inventory
exclusively for rain or sun? In other words, does it seem possible that
Merrill could truly mix his two pure strategies and invest a portion
of the \$250 into each? The game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4in}{YYYY}
& & \multicolumn{2}{c}{Nature} \\
& & Rain & Sun \\ \cline{3-4}
\multirow{2}{.5in}{Merrill} & \gtcol{Rain} & \gtcol{250} & \gtcol{-150} \\ \cline{3-4}
& \gtcol{Sun} & \gtcol{-150} & \gtcol{350} \\ \cline{3-4}
\end{tabularx}
\endgroup
\vspace{.1in}

The best strategy for Merrill is to mix buying for rain and buying
for sun in the ratio 5 to 4. These are the odds. To compute 
Merrill's expected profit (i.e. the value of the game) we use
Merrill's  equilibrium strategy against either of Nature's
pure strategies. Here is the payoff for Merrill against
Nature's strategy of Rain.

\[ \frac{5 \times (250) + 4 \times (-150)}{9} = \$72.22 \]

Merrill could play the odds and choose a pure strategy, but 
note that in this game it is possible for Merrill to physically
mix the strategies. He could invest 5/9 of his \$250 in
rainy--day inventory and invest 4/9 in sunny--day inventory.
So he buys
\[ \frac{5}{9} \left(500 \times .50\right) + \frac{4}{9} \left(100 \times .50\right) = \$161.11 \]
worth of umbrellas and
\[ \frac{4}{9} \left(1000 \times .20\right) = \$88.89 \]
worth of sunglasses so that he enjoys a steady profit of \$72.22.

\section{Exercises}
\begin{enumerate}
	
% This exercise is OK
\item \emph{Rules for decision--making under ignorance.}
  You have the opportunity to go on a
  blind date, but you are hesitant.  You are lonely and would like to
  find the love of your life; however, you dislike awkward
  situations. Furthermore, you find it difficult to estimate the
  probability that this particular blind date will turn out to be the
  love of your life, but you know this probability is
  non-negligible. To be a little more precise, you have the following
  values: finding the love of your life is worth 1000, being in an
  awkward date situation (i.e. being on a date and knowing that you
  will not see the person again) is worth -10, and staying home
  watching Netflix is worth zero.

\begin{enumerate}
\item Formulate a decision problem for deciding whether to go on the
blind date or to stay home.
\item Use the maximin rule to solve the problem.
\item Use the minimax regret rule to solve the problem.
\end{enumerate}

\begin{solution}
\bs The decision problem can be represented with the following table.
\\[.1in]
\begin{tabular}{ccc}
 \multicolumn{3}{c}{decision matrix} \\
 & find love & lots of awkward moments \\ \cline{2-3}
go on date & 1000 & -10 \\
decline date & 0 & 0 
\end{tabular}
\\[.1in] 
The maximin rule tells you to decline the date because it has
the best of all the worst possible outcomes. To use minimax regret, we
form the regret matrix.  \\[.1in]
\begin{tabular}{ccc}
 \multicolumn{3}{c}{regret matrix} \\
 & find love & lots of awkward moments \\ \cline{2-3}
go on date & 0 & -10 \\
decline date & -1000 & 0
\end{tabular}
\\[.1in] Minimax regret tells you to go on the date because the
possibility of not finding love has the most regret.
\end{solution}

% written by Emily
\item \emph{Gardening against nature.} A family is considering growing
  their own garden to save money on fresh vegetables. They have space
  in their yard for the garden but would need to purchase seeds and
  gardening supplies. The family is excited to grow a garden, but they
  know there are a lot of hungry rabbits in their neighborhood that
  might eat their plants before the family can harvest any vegetables
  from them. Money saved by the garden is shown in the following
  table.

\begin{tabular}{rcc}
& \multicolumn{2}{c}{State of Nature} \\
& $s_1$ & $s_2$ \\
& rabbits leave garden alone & rabbits eat garden \\ \cline{2-3}
plant garden & \$400 & -\$100\\
buy vegetables from store & 0 & 0
\end{tabular}

\begin{enumerate}
    \item If the probability that the rabbits leave the garden alone is 0.3, what decision is recommended for the family? What are the expected savings?
    
    \item The family has the option to purchase fast-growing plant seeds (the fast-growing seeds are the same price as regular seeds but they must buy the fast-growing seeds now if they want them because they are in high demand).  With these fast-growing seeds, the family can wait three more weeks to plant their garden. During that time, some scientists will finish their study on the appetites of the local rabbits, and the family will have a better idea about the probability that their garden is eaten by rabbits. They can return the seeds later for a partial refund if they do not use them.
    Let $L$ represent the event the rabbits have large appetites and let $S$ represent
    the event that rabbits have small appetites. Then
    \[
    \begin{matrix}
    P(L)=0.60, & P(s_1 \mid L)=0.15, & P(s_2 \mid L)=0.85,\\
    P(S)=0.40, & P(s_1 \mid S)=0.79, & P(s_2 \mid S)=0.21.
    \end{matrix}
    \]
    What is the optimal decision strategy if the family purchases the fast-growing seeds so they can wait and learn more about the rabbit appetites before making a decision?
    
    \item If \$40\ of the fast-growing seed purchase is non-refundable, should the family purchase the fast-growing seeds? Why or why not? What is the maximum non-refundable amount the family should pay to get the fast-growing seeds?
\end{enumerate}

\begin{solution}
\bs For part a), the expected savings when planting the garden are
\[ 400 \times 0.3  - 100 \times 0.7 = \$50. \]
The savings from not planting the garden are \$0, so based on expected value,
the best decision is to plant the garden.

For part b), if the rabbits have large appetites ($L$), then planting 
the garden would result in -\$25 of expected savings.
If the rabbits have small appetites ($S$), then planting the garden will result in \$295 
of expected savings. 

If L, \[ \$100 \times 0.15 - \$100 \times 0.85 = -\$25 \]
If S, \[ \$400 \times 0.79 - \$100 \times 0.21 = \$295 \]

Not planting will always result in \$0 of savings. 
The optimal decision strategy is to plant the garden if $S$ and buy vegetables 
from the store if $L$.

For part c), we use the optimal decision for each possible event $L$ and $S$. 
The expected savings from purchasing the fast-growing seeds
(but before actually purchasing the seeds) are
\[ \$0 \times 0.60 + \$295 \times 0.40 = \$118 \]
The maximum non-refundable amount that the family should be willing 
to pay for the fast-growing seeds is
\[ \$118 - \$50 = \$68 \]
\end{solution}

% this problem is OK
\item \emph{Using Baye's formula to update a prior belief.}
Curling is a sport in which players slide a stone over ice toward a
target. The association governing the sport has implemented drug
testing. It is believed that 15\% of all curlers use banned drugs to
enhance performance. If a player uses banned drugs, the association
may take away any prizes that the player has won; however, it
undesirable to falsely accuse someone of using banned substances.  The
utilities for each decision and state of nature are

\begin{center}
\begin{tabular}{rrrr}
& drug use & no drug use \\ \cline{2-3}
take away prizes & -100 & -1000 \\
do not & -600 & 0 
\end{tabular}
\end{center}

Notice that there is a small dis-utility for taking prizes away from a drug user
due to bad publicity for the sport. The test to detect drug use is
less than 100\% reliable. In particular, if $D$ indicates that a 
player uses banned drugs, and $+$/$-$ indicate a positive/negative
test result, then the true positive rate and the true negative rate
are
\[
P(+ \mid D) = .97 \quad \text{and} \quad P(- \mid \overline{D}) = .97,
\]
respectively, Given the utilities and the accuracy of the test, what is the best
decision if a player has a positive test result? (The association
wants to maximize expected utility.)

\begin{solution}
\bs First we update the probability of drug use via Baye's formula.
\begin{align*}
P(D \mid +) &= \frac{P(D \cap +)}{P(+)} \\
&= \frac{P(+ \mid D)P(D)}{P(+ \mid D)P(D) + P(+ \mid \overline{D})P(\overline{D})} \\
&= \frac{.97 \times .15}{.97 \times .15 + .03 \times .85} \\
&= .851
\end{align*}
and then we can compute $P(\overline{D} \mid +) = 1 - P(D \mid +) = .149$.
Using these posterior probabilities, the expected utilities are
\begin{align*}
E(\text{take away}) &= (-100)(.851) + (-1000)(.149) = -234 \\
E(\text{do not}) &= (-600)(.851) = -511
\end{align*}
The best decision is to take away prizes when a player tests positive.
\end{solution}

% Emily - expected value and sensitivity analysis
\item \emph {Decisions under risk and sensitivity analysis.}  The
  owners of a popular outdoor furniture company predict that their
  sales will double this coming year. The company is already producing
  the maximum amount of furniture possible in their current
  facility. They are considering expanding their manufacturing
  facility to accommodate the predicted increase in demand. If
  undertaken, the expansion will cost \$\num{500000}. If the demand
  doubles as predicted, revenue will increase by \$\num{800000}.  If
  the predicted increase in demand proves to be too optimistic,
  revenue will increase by only \$\num{250000}.  If the expansion is
  not undertaken, the company will lose \$\num{50000} due to
  out-of-stock orders from agitated customers.  The change in demand
  will be determined by next year's weather; more outdoor furniture is
  sold when the weather is nice.  There is a 0.55 chance of good
  weather, which will result in a doubling of demand. There is a 0.45
  chance of poor weather, which will result in only a slight increase
  in demand.

\begin{enumerate}
\item Should the manufacturing facility be expanded? The owners make
  decisions based on expected value.
\item How does the decision change with the probability of good/poor
  weather? To answer this question, you should perform a sensitivity
  analysis.
\end{enumerate}

\begin{solution}
\bs The decision table for this problem is
\begin{center}
\begin{tabular}{rrr}
      & $0.55$ & $0.45$ \\
      & good weather & poor weather \\ \hline
      expansion & \$\num{300000} & -\$\num{250000} \\
      no expansion & -\$\num{50000} & -\$\num{50000}
\end{tabular}
\end{center}

The expected payoff of each decision is
\begin{align*}
&E(\text{expansion}) = 0.55 \times \$\num{300000}
- 0.45 \times \$\num{250000} = \$\num{52500} \\
&E(\text{no expansion}) = -\$\num{50000}
\end{align*}
The company should expand the facility. As the probability of poor
weather increases, the expected value of the expansion
decreases.  Let $p$ represent the probability of poor weather.
\begin{align*}
E(\text{expansion}) &= \num{300000}(1-p) - \num{250000}p \\
&= \num{300000} - \num{550000}p
\end{align*}
The company should expand the facility as long as
\begin{align*}
E(\text{expansion}) &\geq E(\text{no expansion}) \\
\num{300000} - \num{550000}p &\geq -\num{50000} \\
-\num{5500000}p &\geq -\num{350000} \\
p &\leq \frac{7}{11} \approx .64
\end{align*}
Expanding the facility is the best decision unless the probability of
poor weather is greater than .64.
\end{solution}

% written by Emily
\item \emph{Elimination of dominated strategies.}
Two street vendors, A and B, are located near a major tourist attraction. 
The proportion of customers
captured by each vendor depends on the merchandise sold by that vendor and by
her competitor. A customer gained by one is lost to the other. Each vendor
can stock one of the following: clothing, ice cream, or souvenirs.
The possible strategies and proportion of customers captured are as follows.

\begin{tabular}{l}
If both shops sell souvenirs, A captures 75\% of the customers.\\
If both shops sell clothing, A and B split the customers evenly.\\
If both shops sell ice cream, A and B split the customers evenly.\\
If B sells ice cream and A sells souvenirs, A captures 10\%.\\
If B sells clothing and A sells ice cream, A captures 90\%.\\
If B sells souvenirs and A sells clothing, A captures 10\%.\\
If A sells clothing and B sells ice cream, A captures 100\%.\\
If A sells souvenirs and B sells clothing, A captures 75\%.\\
If A sells ice cream and B sells souvenirs, A captures 40\%.
\end{tabular}

\setlength{\parindent}{0cm}
Model the decision of each vendor as two-person zero-sum game
and find a solution by elimination of dominated strategies.

\begin{solution}
\bs The game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4.5in}{YYYYY}
& & \multicolumn{3}{c}{B} \\
& & clothing & ice cream & souvenirs \\ \cline{3-5}
\multirow{3}{.25in}{A} & \gtcol{clothing} & \gtcol{.50} & \gtcol{1} & \gtcol{.10} \\ \cline{3-5}
& \gtcol{ice cream} & \gtcol{.90} & \gtcol{.50} & \gtcol{.40} \\ \cline{3-5}
& \gtcol{souvenirs} & \gtcol{.75} & \gtcol{.10} & \gtcol{.25} \\ \cline{3-5}
\end{tabularx}
\endgroup
\vspace{.1in}

For A, ice cream strictly dominates souvenirs and for B, souvenirs
strictly dominates clothing, leaving a $2 \times 2$ game.

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4in}{YYYY}
& & \multicolumn{2}{c}{B} \\
& & ice cream & souvenirs \\ \cline{3-4}
\multirow{2}{.25in}{A} & \gtcol{clothing} & \gtcol{1} & \gtcol{.10} \\ \cline{3-4}
& \gtcol{ice cream} & \gtcol{.50} & \gtcol{.40} \\ \cline{3-4}
\end{tabularx}
\endgroup
\vspace{.1in}

Now for B, souvenirs dominates ice cream. Then, A will choose to sell
ice cream over clothing. So, the best strategies for A and B are to
sell ice cream and souvenirs, respectively.  Using this pair of
strategies, A will capture 40\% of the customers.
\end{solution}

% written by Emily to replace Goldsen and Kershaw battle of words
\item \emph{A two-person zero-sum game.}  A professional football
  player believes that the team he plays for should be allocating more
  money to the salaries of the players, so he wants his contract to be
  changed to pay him more. His two options are to play in the upcoming
  season or not play in the upcoming season and hope the team will
  negotiate with him. The team knows that he is a valuable player but
  does not want to pay him more or go through the process of
  negotiations. The team has come up with three options to deal with
  the situation: negotiate, refuse to negotiate and play the season
  without him, or increase the player's salary by a set amount with no
  other negotiations. Keep in mind that the player wants to maximize
  his salary, and the team wants to minimize their costs, which means
  keep salaries as low as possible. The utilities/payoffs to
  the player and to the team are described next.

  If the player plays and the team does not negotiate, the player's
  salary will not change.  If the player does not play and the team
  does not negotiate, the player will find a different job as a
  broadcaster for a payoff of 1 because he is such a well-known
  person. This is bad publicity for the team and hurts their jersey
  sales.  If the player plays but the team still negotiates, the
  player will end up with a payoff of 3.  If the player had
  chosen to not play and the team negotiates, the negotiations will go
  poorly and the player will end up with a payoff of -2 for having to
  deal with costs related to poor publicity.  If the team decides
  increase the player's salary with no negotiations, the player will
  end up with a payoff of 2 no matter what he chooses to do.


  Formulate the 2-by-3 game and determine the best strategy for the
  player and for the team.  Who is most likely to come out ahead in
  this situation?
  
\begin{solution}
\bs The game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4.5in}{YYYYY}
& & \multicolumn{3}{c}{Team} \\
& & negotiate & don't negotiate & increase salary \\ \cline{3-5}
\multirow{2}{.5in}{Player} & \gtcol{play} & \gtcol{3} & \gtcol{0} & \gtcol{2} \\ \cline{3-5}
& \gtcol{don't play} & \gtcol{-2} & \gtcol{1} & \gtcol{2} \\ \cline{3-5}
\end{tabularx}
\endgroup
\vspace{.1in}

The team's strategy of a set
increase is dominated by the strategy to not negotiate, so there is no
reason that they would chose to offer a pre-determined
increase without negotiations. The reduced game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4in}{YYYY}
      & & \multicolumn{2}{c}{Team} \\
      & & {negotiate} & {don't negotiate} \\ \cline{3-4}
      \multirow{2}{.5in}{Player} & \gtcol{play} & \gtcol{3} & \gtcol{0} \\ \cline{3-4}
      & \gtcol{don't play} & \gtcol{-2} & \gtcol{1} \\ \cline{3-4}
\end{tabularx}
\vspace{.1in}
\endgroup

Since there is no saddle point, the best strategies for the player and
for team are mixed. The player should mix the strategies ``play'' and
``don't play'' in the ratio 1:1. The team should mix the strategies
``negotiate'' and ``don't negotiate'' in the ratio 1:5.  Using the
player's mixing ratios against the team's strategy of ``negotiate''
the value of the game is computed as
\[
\frac{1 \times (3) + 1 \times (-2)}{2} = 1/2.
\]
The player is more likely to come out ahead. 
\end{solution}
  
% written by Emily to replace cops and robbers
\item \emph{Marketing strategies.} Two peanut butter companies,
  Doodle's and Lola's, are deciding on their marketing strategy for
  the upcoming year. They know that they are each other's main
  competitor and that the demand for peanut butter is relatively
  constant, so a gain in sales for Doodle's is a loss of sales for
  Lola's. Each company has their standard packaging for peanut butter
  and a new innovative packaging for peanut butter. Both companies
  may produce and sell both types of packaging.  If both
  companies choose to market only their innovative packaging, Doodle's
  will gain an extra 2\%\ of the market's sales.  If both companies
  choose to market their standard packaging, Doodle's will loose 2\%\
  of the market.  If Doodle's markets their innovative product and
  Lola's markets their standard product, Doodle's will gain 10\%\
  of the market.  If Lola's markets their innovative product and
  Doodle's markets their standard product, Doodle's will gain 8\%\
  of the market.
 
\begin{enumerate}
\item Formulate this decision problem as a two-person zero-sum game
  and determine the optimal marketing strategy for each company. Note
  that they are able to change their advertising throughout the year,
  so a mixed strategy is possible.
\item Compute the value of the game. \label{val}
\item Suppose that a member of Doodle's marketing team quits her
  job and goes to work for Lola's. She tells her new co-workers
  about the strategy that Doodle's is planning to use. She is even able to
  tell them the probabiliites with which Doodle's will market their
  standard product and their innovative product. Lola's marketing
  team now knows that Doodles is more likely to market the innovative
  product than the standard product. Armed with this knowledge, they
  choose to only market their standard product, thinking that this
will improve their payoff. Is Lola's argument
  valid? In other words, does the value of the game change if
  Lola's knows Doodle's optimal strategy?
\label{knowledge}
\end{enumerate}

\begin{solution}
\bs The game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{3.25in}{YYYY}
& & \multicolumn{2}{c}{Lola's} \\
& & standard & innovative \\ \cline{3-4}
\multirow{2}{.5in}{Doodle's} & \gtcol{standard} & \gtcol{-2} & \gtcol{8} \\ \cline{3-4}
& \gtcol{innovative} & \gtcol{10} & \gtcol{2} \\ \cline{3-4}
\end{tabularx}
\endgroup
\vspace{.1in}

Note that there is no saddle point, and so the best strategy is mixed.
Doodle's should mix the strategies standard and innovative
in the ratio 4 to 5, while Lola's should mix their strategies of
standard to innovative in the ratio 1 to 2.  The corresponding
probabilities are $(4/9,\,5/9)$ for Doodle's and $(1/3,\,2/3)$ for
Lola's.

To compute the value of the game, note that when
Doodle's markets the standard product, they receive a payoff of -2
with probability 1/3 and payoff of 8 with probability 2/3.  The value
of the game is
\[ \frac{1 \times -2 + 2 \times 8}{3} = \frac{14}{3} = 4.67 \]
On average Doodle's comes out ahead.

Regarding part \ref{knowledge}), the team's thought process is not
valid.  As long as one player sticks to the optimal mixed strategy,
the value of the game does not change.
\end{solution}

% written by Emily to replace the silver dollar
\item \emph{The birthday gift.} Liam's birthday is coming up and he
  can't wait to see what he will get as a gift. Liam's parents want
  the gift to be a surprise, but they always hide gifts in either the
  kitchen or the basement. Liam plans to search for the gift when his
  parents are busy, but he knows that even if he searches the room
  that contains the gift, he may not find it. If the gift is hidden in
  the kitchen and Liam searches the kitchen, he will find the gift
  with probability 0.75.  If the gift in hidden in the basement and he
  searches the basement, then he will find it with probability 0.5.
  If he searches the wrong room, there is no way he will find the
  gift. Assume that the payoff to Liam for finding the gift early is
  the same as the payoff to the parents of keeping the gift a
  surprise.  Formulate this game as a two-person, zero-sum game. Liam
  is the row player and his parents are the column player. Find the
  optimal strategies for both players. \label{sda}

\begin{solution}
  \bs Liam has two possible actions for this game: search the kitchen
  or search the basement. His parents also have two options: hide the
  gift in the kitchen or hide the gift in the basement.  The game is

\begingroup
\setlength{\tabcolsep}{9pt}
\renewcommand*{\arraystretch}{2}
\begin{tabularx}{4in}{YYYY}
& & \multicolumn{2}{c}{Parents} \\
& & hide in kitchen & hide in basement \\ \cline{3-4}
\multirow{2}{.5in}{Liam} & \gtcol{search kitchen} & \gtcol{3/4} & \gtcol{0} \\ \cline{3-4}
& \gtcol{search basement} & \gtcol{0} & \gtcol{1/2} \\ \cline{3-4}
\end{tabularx}
\endgroup
\vspace{.1in}

and the optimal strategy is the same for both players. Each
should play a mixture of $(2/5,~3/5)$.
\end{solution}


% this problem needs to be re-written with a new context.  can we
% think of something more realistic that would have only a few
% discrete values for possible sales?
\item \emph{An inventory problem in a decision problem framework.} 
Daily demand for loaves of bread at a
  grocery store are specified by the following probability
  distribution.

\vspace{.2in}
\begin{tabular}{r|rrrrr}
$n$ & 100 & 150 & 200 & 250 & 300 \\ \hline
$p_n$ & .20 & .25 & .30 & .15 & .10 \\
\end{tabular}

\vspace{.2in}
The store buys a loaf for 55 cents and sells it for \$1.20. Any
unsold loves at the end of the day are marked down and sold for 25
cents each. Assume that the stock level is restricted to one of the
demand levels specified for $p_n$. How many loaves should be
stocked daily in order to maximize expected profit?

\begin{solution}
\bs
Let $Q$ represent the stock quantity and let $z$ represent the
demand. There are two situations. First, if $Q \geq z$
\begin{align*}
E(\text{profit}) &= 1.20z - .55Q + .25(Q-z) \\
&= .95z - .3Q
\end{align*}
Otherwise if $Q < z$, then
\begin{align*}
E(\text{profit}) &= 1.20Q - .55Q\\
&= .65Q
\end{align*}
Using these formulas we can compute the payoffs for each
possible outcome. Using the demand distribution and the
payoffs we can compute the expected payoff for each stock
quantity.

\begin{center}
\begin{tabular}{rr|rrrrrr}
& & \multicolumn{5}{c}{$z$} & \\
& & .2 & .25 & .3 & .15 & .1 & \\
& & 100 & 150 & 200 & 250 & 300 &  $E(\text{payoff})$ \\ \hline
\multirow{5}{*}{$Q$} & 100 & 65 & 65 & 65 & 65 & 65 & 65 \\
& 150 & 50 & 97.5 & 97.5 & 97.5 & 97.5 & 88 \\
& 200 & 35 & 82.5 & 130 & 130 & 130 & {\raise.17ex\hbox{$\scriptstyle\sim$}}99 \\
& 250 & 20 & 67.5 & 115 & 162.5 & 162.5 & 96 \\
& 300 & 5 & 52.5 & 100 & 147.5 & 195 & {\raise.17ex\hbox{$\scriptstyle\sim$}}86
\end{tabular}
\end{center}

The best decision is to stock 200 loaves of bread.
\end{solution}

% this problem needs a new context. the problem itself should not
% change ...  that is, can you represent a preference ordering that is
% naturally specified with two values by a single real value? can we
% think of a modern situation like this? 
\item \emph{Preference orderings and utility functions.}  Suppose that
  you live in a society with the following rules. When you reach age
  20 you will be presented with some alternative choices. The choices
  are of the form $(x;y)$ where $x$ represents the amount of time you
  have left to live, say anywhere from zero to 50 years, and $y$
  represents the amount of time you have left to work, again anywhere
  from zero to 50 years. Both $x$ and $y$ are continuous amounts of
  time, and certainly $x \ge y$. In general you prefer to live longer
  and work less, but you always prefer to live longer no matter how
  long you will work. For example,
  \[
  (x=45~\text{years}; y=35~\text{years}) \succ (x=44~\text{years and}~300~\text{days};y=10~\text{years})
  \]
  The symbol `$\succ$' means ``is preferred to''.  Don't confuse that
  symbol with the mathematical inequality symbol `$>$' (although I
  suspect that the resemblence is intended). Note that, as defined, your
  preference ordering satisfies the completeness and transitivity
  properties (see your textbook). Is it possible to represent your
  preferences with a single (real-valued) number? That is to say, is
  there a function $u(x,y) : (x,y) \mapsto \mathbb{R}$ with the
  following property
  \[
  (x_1,y_1) \succ (x_2,y_2) \implies u(x_1,y_1) > u(x_2,y_2)
  \]
  To make things a little easier, you can restrict $u$ to be a linear
  function of $x$ and $y$. Support your answer with an explanation
  \ldots a formal proof is great, but not required.

\begin{solution}
  \bs I think it is not possible to represent $u$ as a linear
  function of $x$ and $y$. Define $w=50-y$, so that we can represent
  an alternative as $(x,w)$ with the interpretation that more is always
  better, but $x$ still has priority. Now, a linear function will have
  the form
  \[
  u(x,w) = Ax + Bw
  \]
  where $A$ and $B$ are constants.
  It is enough to show a situation where $(x_1;w_1) \succ (x_2;w_2)$
  but that $u(x_1,w_1) < u(x_2,w_2)$. We can write $x_2=x_1-\delta_x$
  and $w_2=w_1+\delta_w$ where $\delta_x > 0$ (so that $x_1>x_2$).
  Now,
  \[
  u(x_1,w_1) = Ax_1 + Bw_1
  \]
  and
  \begin{align*}
    u(x_2,w_2) &= u(x_1-\delta_x,w_1+\delta_w) \\
    &= A(x_1-\delta_x) + B(w_1 + \delta_w) \\
    &= Ax_1 - A\delta_x + Bw_1 + B\delta_w \\
    &= Ax_1 + Bw_1 + (B\delta_w - A\delta_x)
  \end{align*}
  We need only to show that $B\delta_w-A\delta_x > 0$.
  \begin{align*}
    B\delta_w - A\delta_x &> 0 \\
    B\delta_w &> A\delta_x \\
    \frac{\delta_w}{\delta_x} &> \frac{A}{B}
  \end{align*}
  We can choose $\delta_x$ and $\delta_w$ to satisfy the last
  inequality, which means that $u(x_1,w_1) < u(x_2,w_2)$.
\end{solution}

\end{enumerate}
